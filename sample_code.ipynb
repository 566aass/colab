{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8gjNQ2+95gzjvnA55GCSL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/566aass/colab/blob/colab_code/sample_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmrHrvS4Epp8"
      },
      "outputs": [],
      "source": [
        "#CNNN\n",
        "\n",
        "import ee\n",
        "import geemap\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.layers import Dropout,Dense\n",
        "from sklearn.model_selection import train_test_split  # 导入 train_test_split 函数\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import accuracy_score, cohen_kappa_score, confusion_matrix\n",
        "admin_boundaries = ee.FeatureCollection(\"WM/geoLab/geoBoundaries/600/ADM1\")\n",
        "# 筛选山东省的边界\n",
        "shandong_boundary = admin_boundaries.filter(ee.Filter.stringStartsWith('shapeName', 'Shandong')).first()\n",
        "sentinel2_sr = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
        "start_date = '2023-03-01'\n",
        "end_date = '2023-06-01'\n",
        "# 过滤影像集\n",
        "filtered_sentinel2 = sentinel2_sr.filterBounds(shandong_boundary.geometry()) \\\n",
        "                                 .filterDate(start_date, end_date)\n",
        "\n",
        "def cloudShadowMask(img):\n",
        "    qa = img.select('QA60')\n",
        "    cloudBitMask = 1 << 10\n",
        "    cirrusBitMask = 1 << 11\n",
        "    cloudMask = qa.bitwiseAnd(cloudBitMask).eq(0)\n",
        "    cirrusMask = qa.bitwiseAnd(cirrusBitMask).eq(0)\n",
        "    mask = cloudMask.And(cirrusMask)\n",
        "    kernel = ee.Kernel.circle(radius=5, units='pixels')  # 定义一个圆形卷积核\n",
        "    mean_image = img.reduceNeighborhood(ee.Reducer.mean(), kernel).updateMask(mask)  # 计算平均值，并应用掩膜\n",
        "    # 使用平均值填充云像素\n",
        "    filled_image = img.updateMask(mask).unmask(mean_image)\n",
        "\n",
        "    return filled_image\n",
        "\n",
        "filtered_sentinel2 = filtered_sentinel2.map(cloudShadowMask)\n",
        "\n",
        "mosaicked_image = filtered_sentinel2.mosaic()\n",
        "mosaicked_image = mosaicked_image.clip(shandong_boundary.geometry())\n",
        "\n",
        "excel_file = '/content/drive/MyDrive/train/merged_train_data.xlsx'\n",
        "train_df = pd.read_excel(excel_file)\n",
        "\n",
        "X_train = train_df.drop(columns=['class'])\n",
        "y_train = train_df['class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "# 构建CNN\n",
        "model = tf.keras.models.Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(y_train.shape[1], activation='softmax')\n",
        "])\n",
        "# 编译\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train, epochs=30, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', accuracy)"
      ]
    }
  ]
}